<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Select optimal penalty parameter by leave-one-out cross-validation — optPenalty.LOOCV • rags2ridges</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/simplex/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Select optimal penalty parameter by leave-one-out cross-validation — optPenalty.LOOCV"><meta property="og:description" content="This function is now deprecated. Please use optPenalty.kCV instead."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">


    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">rags2ridges</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.2.9</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../articles/rags2ridges.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/CFWP/rags2ridges/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Select optimal penalty parameter by leave-one-out cross-validation</h1>
    <small class="dont-index">Source: <a href="https://github.com/CFWP/rags2ridges/blob/master/R/rags2ridgesDepr.R" class="external-link"><code>R/rags2ridgesDepr.R</code></a></small>
    <div class="hidden name"><code>optPenalty.LOOCV.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>This function is now deprecated. Please use <code>optPenalty.kCV</code> instead.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">optPenalty.LOOCV</span><span class="op">(</span></span>
<span>  <span class="va">Y</span>,</span>
<span>  <span class="va">lambdaMin</span>,</span>
<span>  <span class="va">lambdaMax</span>,</span>
<span>  <span class="va">step</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"Alt"</span>,</span>
<span>  cor <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  target <span class="op">=</span> <span class="fu"><a href="default.target.html">default.target</a></span><span class="op">(</span><span class="fu"><a href="covML.html">covML</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  output <span class="op">=</span> <span class="st">"light"</span>,</span>
<span>  graph <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>


<dl><dt id="arg-y">Y<a class="anchor" aria-label="anchor" href="#arg-y"></a></dt>
<dd><p>Data <code>matrix</code>. Variables assumed to be represented by columns.</p></dd>


<dt id="arg-lambdamin">lambdaMin<a class="anchor" aria-label="anchor" href="#arg-lambdamin"></a></dt>
<dd><p>A <code>numeric</code> giving the minimum value for the penalty
parameter.</p></dd>


<dt id="arg-lambdamax">lambdaMax<a class="anchor" aria-label="anchor" href="#arg-lambdamax"></a></dt>
<dd><p>A <code>numeric</code> giving the maximum value for the penalty
parameter.</p></dd>


<dt id="arg-step">step<a class="anchor" aria-label="anchor" href="#arg-step"></a></dt>
<dd><p>An <code>integer</code> determining the number of steps in moving
through the grid [<code>lambdaMin</code>, <code>lambdaMax</code>].</p></dd>


<dt id="arg-type">type<a class="anchor" aria-label="anchor" href="#arg-type"></a></dt>
<dd><p>A <code>character</code> indicating the type of ridge estimator to be
used. Must be one of: "Alt", "ArchI", "ArchII".</p></dd>


<dt id="arg-cor">cor<a class="anchor" aria-label="anchor" href="#arg-cor"></a></dt>
<dd><p>A <code>logical</code> indicating if the evaluation of the LOOCV score
should be performed on the correlation scale.</p></dd>


<dt id="arg-target">target<a class="anchor" aria-label="anchor" href="#arg-target"></a></dt>
<dd><p>A target <code>matrix</code> (in precision terms) for Type I ridge
estimators.</p></dd>


<dt id="arg-output">output<a class="anchor" aria-label="anchor" href="#arg-output"></a></dt>
<dd><p>A <code>character</code> indicating if the output is either heavy or
light. Must be one of: "all", "light".</p></dd>


<dt id="arg-graph">graph<a class="anchor" aria-label="anchor" href="#arg-graph"></a></dt>
<dd><p>A <code>logical</code> indicating if the grid search for the optimal
penalty parameter should be visualized.</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>A <code>logical</code> indicating if information on progress should
be printed on screen.</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p>An object of class list:</p>
<dl><dt>optLambda</dt>
<dd><p>A <code>numeric</code> giving
the optimal value of the penalty parameter.</p></dd>
 <dt>optPrec</dt>
<dd><p>A <code>matrix</code>
representing the precision matrix of the chosen type (see
<code><a href="ridgeP.html">ridgeP</a></code>) under the optimal value of the penalty parameter.</p></dd>

<dt>lambdas</dt>
<dd><p>A <code>numeric</code> vector representing all values of the
penalty parameter for which cross-validation was performed; Only given when
<code>output = "all"</code>.</p></dd>
 <dt>LLs</dt>
<dd><p>A <code>numeric</code> vector representing the
mean of cross-validated negative log-likelihoods for each value of the
penalty parameter given in <code>lambdas</code>; Only given when <code>output =
"all"</code>.</p></dd>

</dl></div>
    <div id="details">
    <h2>Details</h2>
    <p>Function that selects the optimal penalty parameter for the
<code><a href="ridgeP.html">ridgeP</a></code> call by usage of leave-one-out cross-validation. Its
output includes (a.o.) the precision matrix under the optimal value of the
penalty parameter.</p>
<p>The function calculates a cross-validated negative log-likelihood score
(using a regularized ridge estimator for the precision matrix) for each
value of the penalty parameter contained in the search grid by way of
leave-one-out cross-validation. The value of the penalty parameter that
achieves the lowest cross-validated negative log-likelihood score is deemed
optimal. The penalty parameter must be positive such that <code>lambdaMin</code>
must be a positive scalar. The maximum allowable value of <code>lambdaMax</code>
depends on the type of ridge estimator employed. For details on the type of
ridge estimator one may use (one of: "Alt", "ArchI", "ArchII") see
<code><a href="ridgeP.html">ridgeP</a></code>. The ouput consists of an object of class list (see
below). When <code>output = "light"</code> (default) only the <code>optLambda</code> and
<code>optPrec</code> elements of the list are given.</p>
    </div>
    <div id="note">
    <h2>Note</h2>
    <p>When <code>cor = TRUE</code> correlation matrices are used in the
computation of the (cross-validated) negative log-likelihood score, i.e.,
the leave-one-out sample covariance matrix is a matrix on the correlation
scale. When performing evaluation on the correlation scale the data are
assumed to be standardized. If <code>cor = TRUE</code> and one wishes to used the
default target specification one may consider using <code>target =
default.target(covML(Y, cor = TRUE))</code>. This gives a default target under the
assumption of standardized data.</p>
    </div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p><code><a href="ridgeP.html">ridgeP</a></code>, <code><a href="optPenalty.LOOCVauto.html">optPenalty.LOOCVauto</a></code>,
<code><a href="optPenalty.aLOOCV.html">optPenalty.aLOOCV</a></code>, <br><code><a href="default.target.html">default.target</a></code>,
<code><a href="covML.html">covML</a></code></p></div>
    </div>
    <div id="author">
    <h2>Author</h2>
    <p>Carel F.W. Peeters &lt;carel.peeters@wur.nl&gt;, Wessel N. van Wieringen</p>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">## Obtain some (high-dimensional) data</span></span></span>
<span class="r-in"><span><span class="va">p</span> <span class="op">=</span> <span class="fl">25</span></span></span>
<span class="r-in"><span><span class="va">n</span> <span class="op">=</span> <span class="fl">10</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">333</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">X</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">25</span><span class="op">]</span> <span class="op">=</span> <span class="va">letters</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">25</span><span class="op">]</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">## Obtain regularized precision under optimal penalty</span></span></span>
<span class="r-in"><span><span class="va">OPT</span>  <span class="op">&lt;-</span> <span class="fu">optPenalty.LOOCV</span><span class="op">(</span><span class="va">X</span>, lambdaMin <span class="op">=</span> <span class="fl">.5</span>, lambdaMax <span class="op">=</span> <span class="fl">30</span>, step <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>; <span class="va">OPT</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Perform input checks... </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calculating cross-validated negative log-likelihoods...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.5 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.521112064796442 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.543115568152822 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.56604815028642 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.589949040739926 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.614859125489326 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.640821016885354 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.667879126548165 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.696079741339917 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.725471102545235 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.756103488394997 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.788029300074619 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.821303151363959 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.855981962062195 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.89212505535748 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.929794259307953 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.969054012607691 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.00997147481854 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.0526166412564 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.09706246272843 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.14338497032617 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.19166340548777 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.24198035555219 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.29442189503684 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.34907773288074 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.40604136590477 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.46541023875169 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.52728591057948 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.59177422879317 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.65898551011235 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.72903472928405 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.80204171576394 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.87813135870213 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.95743382058443 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.04008475989428 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.12622556317653 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.21600358689979 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.30957240953135 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.40709209425555 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.5087294627854 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.61465838073554 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.72506005504483 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.84012334395744 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.96004508009247 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.08503040715507 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.21529313086478 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.35105608470152 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.49255151109498 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.64002145870927 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.79371819650269 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.9539046452707 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.12085482741052 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.29485433567656 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.47620082172873 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.66520450530918 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.86218870491866 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.0674903909002 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.28146076187626 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.50446584552545 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.73688712472652 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.97912219014072 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 6.23158542034891 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 6.49470869070685 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 6.76894211213128 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 7.05475480108065 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 7.3526356820475 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 7.66309432393553 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 7.98666181175188 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 8.32389165510583 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 8.67536073506814 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 9.04167029101067 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 9.42344694911443 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 9.8213437943055 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 10.2360414874525 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 10.6682494297369 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 11.1187069761873 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 11.5881847004551 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 12.0774857129934 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 12.587447034895 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 13.11894102974 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 13.6728768959011 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 14.2502022218612 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 14.8519046072019 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 15.4790133520375 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 16.1326012177839 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 16.813786262274 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 17.5237337523593 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 18.2636581572701 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 19.0348252261428 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 19.8385541532693 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 20.6762198347724 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 21.5492552205668 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 22.4591537656302 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 23.4074719847766 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 24.3958321153036 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 25.4259248920664 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 26.499512439728 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 27.6184312871313 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 28.7845955089513 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 30 done </span>
<span class="r-plt img"><img src="optPenalty.LOOCV-1.png" alt="" width="700" height="433"></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $optLambda</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 13.67288</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $optPrec</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A 25 x 25 ridge precision matrix estimate with lambda = 13.672877</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>              a            b           c            d            e            f …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> a  0.754982779 -0.002998480 -0.04858850 -0.002401803  0.013760663  0.001119408 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> b -0.002998480  0.805562115 -0.01556835 -0.006423874 -0.024053290  0.005685832 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> c -0.048588503 -0.015568354  0.75903211 -0.029985881  0.020314633  0.012666613 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> d -0.002401803 -0.006423874 -0.02998588  0.800435062  0.019768171  0.001763517 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> e  0.013760663 -0.024053290  0.02031463  0.019768171  0.766978241 -0.005623105 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> f  0.001119408  0.005685832  0.01266661  0.001763517 -0.005623105  0.810330655 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> … 19 more rows and 19 more columns</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="va">OPT</span><span class="op">$</span><span class="va">optLambda</span>  <span class="co"># Optimal penalty</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 13.67288</span>
<span class="r-in"><span><span class="va">OPT</span><span class="op">$</span><span class="va">optPrec</span>    <span class="co"># Regularized precision under optimal penalty</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A 25 x 25 ridge precision matrix estimate with lambda = 13.672877</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>              a            b           c            d            e            f …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> a  0.754982779 -0.002998480 -0.04858850 -0.002401803  0.013760663  0.001119408 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> b -0.002998480  0.805562115 -0.01556835 -0.006423874 -0.024053290  0.005685832 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> c -0.048588503 -0.015568354  0.75903211 -0.029985881  0.020314633  0.012666613 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> d -0.002401803 -0.006423874 -0.02998588  0.800435062  0.019768171  0.001763517 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> e  0.013760663 -0.024053290  0.02031463  0.019768171  0.766978241 -0.005623105 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> f  0.001119408  0.005685832  0.01266661  0.001763517 -0.005623105  0.810330655 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> … 19 more rows and 19 more columns</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">## Another example with standardized data</span></span></span>
<span class="r-in"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html" class="external-link">scale</a></span><span class="op">(</span><span class="va">X</span>, center <span class="op">=</span> <span class="cn">TRUE</span>, scale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">OPT</span>  <span class="op">&lt;-</span> <span class="fu">optPenalty.LOOCV</span><span class="op">(</span><span class="va">X</span>, lambdaMin <span class="op">=</span> <span class="fl">.5</span>, lambdaMax <span class="op">=</span> <span class="fl">30</span>, step <span class="op">=</span> <span class="fl">100</span>, cor <span class="op">=</span> <span class="cn">TRUE</span>,</span></span>
<span class="r-in"><span>                         target <span class="op">=</span> <span class="fu"><a href="default.target.html">default.target</a></span><span class="op">(</span><span class="fu"><a href="covML.html">covML</a></span><span class="op">(</span><span class="va">X</span>, cor <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>; <span class="va">OPT</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Perform input checks... </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Calculating cross-validated negative log-likelihoods...</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.5 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.521112064796442 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.543115568152822 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.56604815028642 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.589949040739926 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.614859125489326 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.640821016885354 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.667879126548165 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.696079741339917 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.725471102545235 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.756103488394997 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.788029300074619 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.821303151363959 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.855981962062195 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.89212505535748 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.929794259307953 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 0.969054012607691 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.00997147481854 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.0526166412564 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.09706246272843 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.14338497032617 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.19166340548777 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.24198035555219 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.29442189503684 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.34907773288074 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.40604136590477 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.46541023875169 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.52728591057948 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.59177422879317 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.65898551011235 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.72903472928405 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.80204171576394 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.87813135870213 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 1.95743382058443 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.04008475989428 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.12622556317653 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.21600358689979 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.30957240953135 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.40709209425555 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.5087294627854 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.61465838073554 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.72506005504483 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.84012334395744 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 2.96004508009247 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.08503040715507 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.21529313086478 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.35105608470152 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.49255151109498 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.64002145870927 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.79371819650269 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 3.9539046452707 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.12085482741052 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.29485433567656 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.47620082172873 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.66520450530918 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 4.86218870491866 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.0674903909002 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.28146076187626 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.50446584552545 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.73688712472652 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 5.97912219014072 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 6.23158542034891 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 6.49470869070685 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 6.76894211213128 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 7.05475480108065 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 7.3526356820475 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 7.66309432393553 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 7.98666181175188 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 8.32389165510583 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 8.67536073506814 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 9.04167029101067 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 9.42344694911443 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 9.8213437943055 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 10.2360414874525 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 10.6682494297369 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 11.1187069761873 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 11.5881847004551 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 12.0774857129934 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 12.587447034895 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 13.11894102974 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 13.6728768959011 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 14.2502022218612 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 14.8519046072019 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 15.4790133520375 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 16.1326012177839 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 16.813786262274 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 17.5237337523593 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 18.2636581572701 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 19.0348252261428 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 19.8385541532693 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 20.6762198347724 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 21.5492552205668 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 22.4591537656302 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 23.4074719847766 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 24.3958321153036 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 25.4259248920664 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 26.499512439728 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 27.6184312871313 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 28.7845955089513 done </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lambda = 30 done </span>
<span class="r-plt img"><img src="optPenalty.LOOCV-2.png" alt="" width="700" height="433"></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $optLambda</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1.729035</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> $optPrec</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A 25 x 25 ridge precision matrix estimate with lambda = 1.729035</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>              a            b           c            d           e            f …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> a  0.870558731  0.005799602 -0.10887022  0.020620932  0.02747321 -0.030649123 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> b  0.005799602  0.858543312 -0.05826257 -0.060673303 -0.10951470  0.013668617 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> c -0.108870222 -0.058262566  0.92295982 -0.108621345  0.04811302  0.035537758 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> d  0.020620932 -0.060673303 -0.10862134  0.870451897  0.05721630 -0.008132546 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> e  0.027473206 -0.109514703  0.04811302  0.057216296  0.90403666 -0.041437493 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> f -0.030649123  0.013668617  0.03553776 -0.008132546 -0.04143749  0.861873688 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> … 19 more rows and 19 more columns</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-in"><span><span class="va">OPT</span><span class="op">$</span><span class="va">optLambda</span>  <span class="co"># Optimal penalty</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1.729035</span>
<span class="r-in"><span><span class="va">OPT</span><span class="op">$</span><span class="va">optPrec</span>    <span class="co"># Regularized precision under optimal penalty</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> A 25 x 25 ridge precision matrix estimate with lambda = 1.729035</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>              a            b           c            d           e            f …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> a  0.870558731  0.005799602 -0.10887022  0.020620932  0.02747321 -0.030649123 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> b  0.005799602  0.858543312 -0.05826257 -0.060673303 -0.10951470  0.013668617 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> c -0.108870222 -0.058262566  0.92295982 -0.108621345  0.04811302  0.035537758 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> d  0.020620932 -0.060673303 -0.10862134  0.870451897  0.05721630 -0.008132546 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> e  0.027473206 -0.109514703  0.04811302  0.057216296  0.90403666 -0.041437493 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> f -0.030649123  0.013668617  0.03553776 -0.008132546 -0.04143749  0.861873688 …</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> … 19 more rows and 19 more columns</span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Carel F.W. Peeters, Anders Ellern Bilgrau, Wessel N. van Wieringen.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

      </footer></div>






  </body></html>

